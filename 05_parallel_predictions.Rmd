---
title: "R Notebook"
output: html_notebook
---

#### Authors: Winona Wijaya, Martin Ostrowski, Deepa Varkey and Mark Brown
#### Date: 20190418
#### email: martin.ostrowski@uts.edu.au

This workbook describes a parallel function for generating spatial predictions for pre-computed models against the CARS weekly and monthly climatologies

The workflow for producing the models is documented [here](./01_model_preparation.Rmd)
The workflow for extracting and preparing the CARS data is documented [here](./02_extract_cars_data.Rmd) 

```{r}
library(gbm)
library(dismo)
library(tidyverse)
library(parallel)


setwd("~/data/RDS.1/")
my.models<-list.files(pattern = "am16s.")
nmods<-length(my.models)
cars.weekly<-read_csv('cars.weekly.v1.csv')

clust <- makeCluster(10)


predict.zotus <- function(k) {
setwd("~/data/RDS.3/")
my.mod <- readRDS(my.models[k])
preds.cars.weekly <- tryCatch(predict.gbm(my.mod, cars.weekly, n.trees=my.mod$gbm.call$best.trees, type="response"), error=function(e) { print(e); return(NULL) })
if (!is.null(preds.cars.weekly)) {
mod.name<-my.mod[[28]][5][[1]]
preds.cars.weekly <- as.data.frame(preds.cars.weekly)
colnames(preds.cars.weekly) <- mod.name
return(preds.cars.weekly)
} else {
    return(NULL)
  }
}

clusterExport(clust, c("predict.gbm", "cars.weekly", "saveRDS", "predict.zotus", "my.models"))


res1<-parLapply(cl = clust, x:y, function(k) predict.zotus(k))


***
  
  ```{r}
library(gbm)
library(dismo)
library(tidyverse)
library(parallel)
# library(lubridate)
# library(geosphere)


setwd("~/data/uniques/winona/rds_18")
my.models <- list.files(pattern = "am18s")
nmods <- length(my.models)

cars.weekly <- read_csv("~/data/uniques/winona/cars.weekly.v1.csv")
# cars.weekly$daylength <- (daylength(cars.weekly$lat,as.Date(cars.weekly$day,origin = "2019-01-01"))*60)
# colnames(cars.weekly)[7] <- "silicate"
# write_csv(cars.weekly,"cars.weekly.v1.csv")
preds.cars.weekly <- matrix(nrow=nrow(cars.weekly), ncol=nmods)

my.mods<-vector('list', length=nmods)

eval.data.out<-vector('double', nmods)

contributions<-matrix(nrow=11, ncol=nmods)
rownames(contributions)<-c("temp","sal","silicate","depth","strat","N", "n.p", "P", "nstar", "daylength", "bottom_depth")
  
predict.zotus <- function(k) {
setwd("~/data/uniques/winona/rds_18")
my.mod <- readRDS(my.models[k])
preds.cars.weekly <- predict.gbm(my.mod, cars.weekly, n.trees=my.mod$gbm.call$best.trees, type="response")
mod.name<-my.mod[[28]][5][[1]]
preds.cars.weekly <- as.data.frame(preds.cars.weekly)
colnames(preds.cars.weekly) <- mod.name
return(preds.cars.weekly)
}

eval.zotus <- function(l){
  my.mod <- readRDS(my.models[l])
  mod.name<-my.mod[[28]][5][[1]]
  cv <- my.mod$cv.statistics$correlation.mean
  cvse <- my.mod$cv.statistics$correlation.se
  ntrees <- my.mod$n.trees
  contributions <- my.mod[[32]][c("temp","sal","silicate","depth","strat","N", "n.p", "P", "nstar", "daylength", "bottom_depth"),2]
  eval.temp <- c(cv, cvse, ntrees, contributions)
  eval.temp <- as.data.frame(eval.temp)
  eval.temp <- t(eval.temp)
  row.names(eval.temp) <- mod.name
  colnames(eval.temp) <- c("cv", "cvse", "ntrees","temp","sal","silicate","depth","strat","N", "n.p", "P", "nstar", "daylength", "bottom_depth")
  return(eval.temp)
}


clust <- makeCluster(8)
	
clusterExport(clust, c("my.models", "nmods", "cars.weekly", "preds.cars.weekly", "my.mods", "eval.data.out", "cv", "cvse", "ntrees", "contributions", "predict.zotus", "predict.gbm", "readRDS", "predict.zotus", "eval.zotus"))

predictions <- parLapply(cl = clust, 1:10, function(i) predict.zotus(i))
predictions <- do.call(cbind,predictions)

evaluations <- parLapply(cl = clust, 1:10, function(i) eval.zotus(i))
evaluations <- do.call(rbind,evaluations)
zOTU <- rownames(evaluations)
evaluations <- cbind(zOTU, evaluations)
  
write_csv(evaluations, "evaluationssss.csv")
write_csv(predictions, "predictionssss.csv")

stopCluster(clust)

```
